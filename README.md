# Consistent Image Synthesis for T2I Personalization 

**ğŸ“¢2024ë…„ ì—¬ë¦„ [AIKU](https://github.com/AIKU-Official) í™œë™ìœ¼ë¡œ ì§„í–‰í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.**

**ğŸ‰2024ë…„ ì—¬ë¦„ AIKU Conference ì—´ì‹¬íˆìƒ ìˆ˜ìƒ!**

## ì†Œê°œ

ë³¸ í”„ë¡œì íŠ¸ëŠ” 
T2I personalization taskëŠ” ì‚¬ìš©ì ì œê³µ reference imageë¥¼ ê¸°ë°˜ìœ¼ë¡œ T2I diffusion ëª¨ë¸ì„ ì‚¬ìš©ì ë§ì¶¤í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª‡ ì¥ì˜ reference imageì™€ text promptë¥¼ ì œê³µí•˜ë©´ ë‹¤ì–‘í•œ pose, view, backgroundì—ì„œ ëŒ€ìƒì˜ ìƒˆë¡œìš´ ë Œë”ë§ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì€ ê³ ìœ í•œ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ìƒì„ ë‚˜íƒ€ë‚´ë©°, í…ìŠ¤íŠ¸ ì„ë² ë”© ìì²´ë‚˜ í™•ì‚° ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ìµœì í™”í•˜ì—¬ ëŒ€ìƒì„ í‘œí˜„í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ì¢…ì¢… ìƒ‰ìƒ, í…ìŠ¤ì²˜ ë° ëª¨ì–‘ê³¼ ê°™ì€ ëŒ€ìƒì˜ ì™¸ê´€ì„ ì •í™•í•˜ê²Œ ëª¨ë°©í•˜ëŠ” ë° ì‹¤íŒ¨í•©ë‹ˆë‹¤. ì´ëŠ” í…ìŠ¤íŠ¸ ì„ë² ë”©ì´ ëŒ€ìƒì˜ ì‹œê°ì  ì™¸ê´€ì„ í‘œí˜„í•˜ëŠ” ë° ì¶©ë¶„í•œ spatial representationì„ ê°€ì§€ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

## íŒ€ì›

| íŒ€ì›                            | ì—­í•                                        |
| -------------------------------------- | ---------------------------------------- |
| [ê¹€ë¯¼ì¬](https://github.com/kwjames98)*      | Inference, Code analysis(Textual Inversion),  Paper(Abstract, Introduction, Related Works, Preliminary, Method)  |
| [ê¹€ë¯¼ì˜](https://github.com/EuroMinyoung186)     | Code analysis(Cross attention map), Inference, Evaluation(MasaCtrl), Distributive processing, Paper(Experiments, Conclusion) |
| [ì§€ë™í™˜](https://github.com/zheedong)                          | Code analysis(Textual Inversion, Cross attention map), Inference, Paper(Reference) |
| [í™©ì •í˜„](https://github.com/imjunghyunee)                           | Code analysis(Textual Inversion), Paper(Experiments, Conclusion), Inference |

## ì°¸ê³  ë…¼ë¬¸

> **Custom Diffusion** [[repo]](https://github.com/adobe-research/custom-diffusion)
>
> _Proposed in [â€œMulti-Concept Customization of Text-to-Image Diffusionâ€](https://arxiv.org/abs/2212.04488),
> CVPR 2023

> **MasaCtrl** [[repo]](https://github.com/TencentARC/MasaCtrl)
>
> _Proposed in [â€œMasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editingâ€](https://arxiv.org/abs/2304.08465),
> ICCV 2023

### MasaCtrl Architecture
<p align="center">
    <img src = "./images/MasaCtrl architecture.PNG"
        style = "width: 70%">
</p>


## ë°©ë²•ë¡  1: Cross Attention Map 


<p align="center">
    <img src = "./images/cross attention map.PNG"
        style = "width: 50%">
</p>

MasaCtrlì€ layout í˜•ì„±ì„ ìœ„í•´ S step ì´í›„ denoising U-Net decoder ì˜ L layerì˜ cross attention map ì„ average í•œ 16x16xN textual token correlated attention mapì„ ì–»ì€ í›„, Nì— ëŒ€í•´ì„œ average ë¥¼ í†µí•´ 16x16 attention mapì„ ì–»ìŠµë‹ˆë‹¤. ê·¸ í›„ pixel ë³„ë¡œ thresholding í•´ì„œ masked-guided mutual self attentionì„ ìœ„í•œ foreground/background binary maskë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì €í¬ëŠ” Encoderë¶€ë¶„ì—ì„œ ë˜ëŠ” Decoderë¶€ë¶„ì—ì„œ, ê·¸ë¦¬ê³  Encoderë‚˜ Decoderì˜ ì¼ë¶€ cross attention mapì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ í†µí•´ cross attention mapì´ ì´ë¯¸ì§€ ìƒì„±ì— ë¼ì¹˜ëŠ” ì˜í–¥ ë¹„êµí–ˆìŠµë‹ˆë‹¤. 

## ë°©ë²•ë¡  2: Denoising Step and layer


ë°©ë²•ë¡  1ì—ì„œ Decoderê°€ Encoderë³´ë‹¤ Consistency ìœ ì§€ë¥¼ ì˜í•˜ê³ , ì‹¤ì œ CLIP ê¸°ë°˜ scoreì—ì„œë„ ì ìˆ˜ê°€ ë†’ì•˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ Encoderê°€ Text alignmentì—ì„œëŠ” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
ë˜í•œ Encoderì˜ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ í•©ì¹˜ë©´, sourceì—ì„œ ê°€ë ¤ì§„ ë¶€ë¶„ì„ ì¶”ë¡ í•´ì„œ ë§Œë“¤ì–´ë‚´ëŠ” ëŠ¥ë ¥ì„ ë³´ì˜€ê³ , Decoderì—ëŠ” ê·¸ ë¶€ë¶„ì´ ì‚­ì œë˜ì„œ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ìƒì„±ì„ í•˜ëŠ” Decoderì˜ ê³¼ì •ì—ì„œ Key Valueë¡œ sourceë¥¼ ì“°ë‹¤ë³´ë‹ˆ, ìƒì„±í•  ë•Œ ì˜¤íˆë ¤ ì›ë³¸ì— ëŒ€í•œ ì •ë³´ë§Œì´ ê°•ë ¥í•˜ê²Œ ë“¤ì–´ê°€ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤.

ê·¸ì— ëŒ€í•œ í•´ê²°ì±…ìœ¼ë¡œ Stepì„ 4ë¶€í„° 50ì´ ì•„ë‹ˆë¼ 4ë¶€í„° 20 / 4ë¶€í„° 25 ë“± ìµœì¢… stepì„ ì¤„ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. Encoderë¥¼ í™œìš©í•˜ë©´ ì˜ë¦¬ëŠ” ë¶€ë¶„ì´ ì—†ê² ì§€ë§Œ, Consistencyê°€ ìœ ì§€ë˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— ì‚¬ìš©í•˜ê¸° í˜ë“¤ì–´ ë³´ì˜€ê³ , Decoderë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ìµœëŒ€í•œ ì˜ë¦¬ëŠ” ë¶€ë¶„ì´ ì—†ê²Œ ë§Œë“¤ë ¤ë©´ ê³„ì†í•´ì„œ mutual self attentionì„ í•  ê²Œ ì•„ë‹ˆë¼ ì–´ëŠ ì •ë„ê¹Œì§€ëŠ” mutual self attentionì„ ì£¼ê³ , ê·¸ ì´í›„ë¡œëŠ” Text conditionalë§Œ ì˜í–¥ì„ ì£¼ê²Œí•˜ë©´, ì´ˆê¸°ì— sourceì™€ ê°™ì€ í˜•íƒœë¡œ ì„¸íŒ…ì„ í•´ì£¼ì–´ textì— ì˜ì¡´í•˜ì—¬ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë˜ì§€ ì•Šì„ê¹Œë€ ìƒê°ì—ì„œ ì°©ì•ˆí–ˆìŠµë‹ˆë‹¤.


## ì˜ˆì‹œ ê²°ê³¼

### final stepë³„ image ì°¨ì´
<img src = "./images/corgi_final_step.png">

#### Encoderì™€ Decoderë³„ image ì°¨ì´
<img src = "./images/corgi_layer_type.png">

#### step ê°„ê²© ë³„ image ì°¨ì´
<img src = "./images/corgi_skip_step_interval.png">

#### start stepë³„ image ì°¨ì´
<img src = "./images/corgi_start_step.png">

#### final_stepë³„ text-alignmentì™€ image-alignment ì‚¬ì´ì˜ ê´€ê³„
<img src = "./images/final_step_plot.png">

#### skip_stepë³„ text-alignmentì™€ image-alignment ì‚¬ì´ì˜ ê´€ê³„ 
<img src = "./images/skip_step_interval_plot.png">

#### start_stepë³„ text-alignmentì™€ image-alignment ì‚¬ì´ì˜ ê´€ê³„ 
<img src = "./images/start_step_plot.png">


